{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "\n",
    "trimmed_file_path = 'trimmed_data.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol: https\n",
      "Domain: test.co.uk\n",
      "Directory: \n",
      "File: \n",
      "Parameters: ?help=1\n"
     ]
    }
   ],
   "source": [
    "url_regex = \"^(https?|ftp):\\/\\/([^\\/]+)\\/(([^\\/?]+\\/)*)?([^\\/?]+\\.\\w+)?(\\?([^=]+=[^&]+)(&([^=]+=[^&]+))*)?$\"\n",
    "url = \"https://test.co.uk/?help=1\"\n",
    "match = re.match(url_regex, url)\n",
    "\n",
    "def extract_urls_from_email(email_content):\n",
    "    # Regex to match URLs\n",
    "    url_pattern = r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "\n",
    "    # Find all URLs in the email content\n",
    "    urls = re.findall(url_pattern, email_content)\n",
    "    return urls\n",
    "\n",
    "def getNumSuspiciousKeywords(email_content):\n",
    "    # need to somehow account for bypass word filter by using different letter\n",
    "    text_lower = email_content.lower()\n",
    "    keywords = [\"urgent update\", \"pay now\"]\n",
    "    keyword_count = 0\n",
    "    \n",
    "    # Iterate through the keywords and count occurrences in the text\n",
    "    for keyword in keywords:\n",
    "        # Check if the keyword (case-insensitive) is present in the text\n",
    "        if keyword.lower() in text_lower:\n",
    "            keyword_count += 1\n",
    "    \n",
    "    return keyword_count\n",
    "\n",
    "def getNumShortedUrls(email_content):\n",
    "    short_domains = ['goo.gl', 'jmp.by']\n",
    "    pattern = r'https?://(?:{})/\\S+'.format('|'.join(re.escape(domain) for domain in short_domains))\n",
    "    urls = re.findall(pattern, email_content)\n",
    "    \n",
    "    # Count the number of URLs found\n",
    "    return len(urls)\n",
    "\n",
    "def getNumIpAddresses(email_content):\n",
    "    ipv4_regex = \"\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b\"\n",
    "    ipv6_regex = \"(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))\"\n",
    "    \n",
    "    ipv4_addresses = re.findall(ipv4_regex, email_content)\n",
    "    ipv6_addresses = re.findall(ipv6_regex, email_content)\n",
    "    \n",
    "    return len(ipv4_addresses) + len(ipv6_addresses)\n",
    "\n",
    "if match:\n",
    "    protocol = match.group(1)\n",
    "    domain = match.group(2)\n",
    "    directory = match.group(3) if match.group(3) else \"\"  # Handle optional directory\n",
    "    file = match.group(4) if match.group(4) else \"\"\n",
    "    parameters = match.group(6) if match.group(6) else \"\"  # Handle optional parameters\n",
    "\n",
    "    print(\"Protocol:\", protocol)\n",
    "    print(\"Domain:\", domain)\n",
    "    print(\"Directory:\", directory)\n",
    "    print(\"File:\", file)\n",
    "    print(\"Parameters:\", parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from https://data.mendeley.com/datasets/c2gw7fy2j4/3/files/2cb9aa39-5aa5-4c84-a455-a8dbcc03526e\n",
    "\n",
    "# 0 stands for legitimate\n",
    "# 1 stands for phishing\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "#LOCALHOST_PATH = \"/var/www/html/\"\n",
    "HINTS = ['wp', 'login', 'includes', 'admin', 'content', 'site', 'images', 'js', 'alibaba', 'css', 'myaccount', 'dropbox', 'themes', 'plugins', 'signin', 'view']\n",
    "\n",
    "allbrand_txt = open(\"data/allbrands.txt\", \"r\")\n",
    "\n",
    "def __txt_to_list(txt_object):\n",
    "    list = []\n",
    "    for line in txt_object:\n",
    "        list.append(line.strip())\n",
    "    txt_object.close()\n",
    "    return list\n",
    "\n",
    "allbrand = __txt_to_list(allbrand_txt)\n",
    "#print(allbrand)\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Having IP address in hostname\n",
    "#################################################################################################################################\n",
    "\n",
    "def having_ip_address(url):\n",
    "    match = re.search(\n",
    "        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n",
    "        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n",
    "        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)|'  # IPv4 in hexadecimal\n",
    "        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}|'\n",
    "        '[0-9a-fA-F]{7}', url)  # Ipv6\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#################################################################################################################################\n",
    "#               URL hostname length \n",
    "#################################################################################################################################\n",
    "\n",
    "def url_length(url):\n",
    "    return len(url) \n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               URL shortening\n",
    "#################################################################################################################################\n",
    "\n",
    "def shortening_service(full_url):\n",
    "    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n",
    "                      'tr\\.im|link\\.zip\\.net',\n",
    "                      full_url)\n",
    "    if match:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count at (@) symbol at base url\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_at(base_url):\n",
    "     return base_url.count('@')\n",
    " \n",
    "#################################################################################################################################\n",
    "#               Count comma (,) symbol at base url\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_comma(base_url):\n",
    "     return base_url.count(',')\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count dollar ($) symbol at base url\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_dollar(base_url):\n",
    "     return base_url.count('$')\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Having semicolumn (;) symbol at base url\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_semicolumn(url):\n",
    "     return url.count(';')\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count (space, %20) symbol at base url (Das'19)\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_space(base_url):\n",
    "     return base_url.count(' ')+base_url.count('%20')\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count and (&) symbol at base url (Das'19)\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_and(base_url):\n",
    "     return base_url.count('&')\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count redirection (//) symbol at full url\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_double_slash(full_url):\n",
    "    list=[x.start(0) for x in re.finditer('//', full_url)]\n",
    "    if list[len(list)-1]>6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    return full_url.count('//')\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count slash (/) symbol at full url\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_slash(full_url):\n",
    "    return full_url.count('/')\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count equal (=) symbol at base url\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_equal(base_url):\n",
    "    return base_url.count('=')\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count percentage (%) symbol at base url (Chiew2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_percentage(base_url):\n",
    "    return base_url.count('%')\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count exclamation (?) symbol at base url\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_exclamation(base_url):\n",
    "    return base_url.count('?')\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count underscore (_) symbol at base url\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_underscore(base_url):\n",
    "    return base_url.count('_')\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count dash (-) symbol at base url\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_hyphens(base_url):\n",
    "    return base_url.count('-')\n",
    "\n",
    "#################################################################################################################################\n",
    "#              Count number of dots in hostname\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_dots(hostname):\n",
    "    return hostname.count('.')\n",
    "\n",
    "#################################################################################################################################\n",
    "#              Count number of colon (:) symbol\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_colon(url):\n",
    "    return url.count(':')\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count number of stars (*) symbol (Srinivasa Rao'19)\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_star(url):\n",
    "    return url.count('*')\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count number of OR (|) symbol (Srinivasa Rao'19)\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_or(url):\n",
    "    return url.count('|')\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Path entension != .txt\n",
    "#################################################################################################################################\n",
    "\n",
    "def path_extension(url_path):\n",
    "    if url_path.endswith('.txt'):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Having multiple http or https in url path\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_http_token(url_path):\n",
    "    return url_path.count('http')\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Uses https protocol\n",
    "#################################################################################################################################\n",
    "\n",
    "def https_token(scheme):\n",
    "    if scheme == 'https':\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Ratio of digits in hostname \n",
    "#################################################################################################################################\n",
    "\n",
    "def ratio_digits(hostname):\n",
    "    return len(re.sub(\"[^0-9]\", \"\", hostname))/len(hostname)\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Count number of digits in domain/subdomain/path\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_digits(line):\n",
    "    return len(re.sub(\"[^0-9]\", \"\", line))\n",
    "\n",
    "#################################################################################################################################\n",
    "#              Checks if tilde symbol exist in webpage URL (Chiew2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_tilde(full_url):\n",
    "    if full_url.count('~')>0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               number of phish-hints in url path \n",
    "#################################################################################################################################\n",
    "\n",
    "def phish_hints(url_path):\n",
    "    count = 0\n",
    "    for hint in HINTS:\n",
    "        count += url_path.lower().count(hint)\n",
    "    return count\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Check if TLD exists in the path \n",
    "#################################################################################################################################\n",
    "\n",
    "def tld_in_path(tld, path):\n",
    "    if path.lower().count(tld)>0:\n",
    "        return 1\n",
    "    return 0\n",
    "    \n",
    "#################################################################################################################################\n",
    "#               Check if tld is used in the subdomain \n",
    "#################################################################################################################################\n",
    "\n",
    "def tld_in_subdomain(tld, subdomain):\n",
    "    if subdomain.count(tld)>0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Check if TLD in bad position (Chiew2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def tld_in_bad_position(tld, subdomain, path):\n",
    "    if tld_in_path(tld, path)== 1 or tld_in_subdomain(tld, subdomain)==1:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Abnormal subdomain starting with wwww-, wwNN\n",
    "#################################################################################################################################\n",
    "\n",
    "def abnormal_subdomain(url):\n",
    "    if re.search('(http[s]?://(w[w]?|\\d))([w]?(\\d|-))',url):\n",
    "        return 1\n",
    "    return 0\n",
    "    \n",
    "\n",
    "#################################################################################################################################\n",
    "#               Number of redirection \n",
    "#################################################################################################################################\n",
    "\n",
    "def count_redirection(page):\n",
    "    return len(page.history)\n",
    "    \n",
    "#################################################################################################################################\n",
    "#               Number of redirection to different domains\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_external_redirection(page, domain):\n",
    "    count = 0\n",
    "    if len(page.history) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        for i, response in enumerate(page.history,1):\n",
    "            if domain.lower() not in response.url.lower():\n",
    "                count+=1          \n",
    "            return count\n",
    "\n",
    "    \n",
    "#################################################################################################################################\n",
    "#               Is the registered domain created with random characters (Sahingoz2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "from word_with_nlp import nlp_class\n",
    "\n",
    "def random_domain(domain):\n",
    "        nlp_manager = nlp_class()\n",
    "        return nlp_manager.check_word_random(domain)\n",
    "    \n",
    "#################################################################################################################################\n",
    "#               Consecutive Character Repeat (Sahingoz2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def char_repeat(words_raw):\n",
    "    \n",
    "        def __all_same(items):\n",
    "            return all(x == items[0] for x in items)\n",
    "\n",
    "        repeat = {'2': 0, '3': 0, '4': 0, '5': 0}\n",
    "        part = [2, 3, 4, 5]\n",
    "\n",
    "        for word in words_raw:\n",
    "            for char_repeat_count in part:\n",
    "                for i in range(len(word) - char_repeat_count + 1):\n",
    "                    sub_word = word[i:i + char_repeat_count]\n",
    "                    if __all_same(sub_word):\n",
    "                        repeat[str(char_repeat_count)] = repeat[str(char_repeat_count)] + 1\n",
    "        return  sum(list(repeat.values()))\n",
    "    \n",
    "#################################################################################################################################\n",
    "#               puny code in domain (Sahingoz2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def punycode(url):\n",
    "    if url.startswith(\"http://xn--\") or url.startswith(\"http://xn--\"):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#################################################################################################################################\n",
    "#               domain in brand list (Sahingoz2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def domain_in_brand(domain):\n",
    "        \n",
    "    if domain in allbrand:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    " \n",
    "import Levenshtein\n",
    "def domain_in_brand1(domain):\n",
    "    for d in allbrand:\n",
    "        if len(Levenshtein.editops(domain.lower(), d.lower()))<2:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               brand name in path (Srinivasa-Rao2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def brand_in_path(domain,path):\n",
    "    for b in allbrand:\n",
    "        if '.'+b+'.' in path and b not in domain:\n",
    "           return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               count www in url words (Sahingoz2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def check_www(words_raw):\n",
    "        count = 0\n",
    "        for word in words_raw:\n",
    "            if not word.find('www') == -1:\n",
    "                count += 1\n",
    "        return count\n",
    "    \n",
    "#################################################################################################################################\n",
    "#               count com in url words (Sahingoz2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def check_com(words_raw):\n",
    "        count = 0\n",
    "        for word in words_raw:\n",
    "            if not word.find('com') == -1:\n",
    "                count += 1\n",
    "        return count\n",
    "\n",
    "#################################################################################################################################\n",
    "#               check port presence in domain\n",
    "#################################################################################################################################\n",
    "\n",
    "def port(url):\n",
    "    if re.search(\"^[a-z][a-z0-9+\\-.]*://([a-z0-9\\-._~%!$&'()*+,;=]+@)?([a-z0-9\\-._~%]+|\\[[a-z0-9\\-._~%!$&'()*+,;=:]+\\]):([0-9]+)\",url):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "#################################################################################################################################\n",
    "#               length of raw word list (Sahingoz2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def length_word_raw(words_raw):\n",
    "    return len(words_raw) \n",
    "\n",
    "#################################################################################################################################\n",
    "#               count average word length in raw word list (Sahingoz2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def average_word_length(words_raw):\n",
    "    if len(words_raw) ==0:\n",
    "        return 0\n",
    "    return sum(len(word) for word in words_raw) / len(words_raw)\n",
    "\n",
    "#################################################################################################################################\n",
    "#               longest word length in raw word list (Sahingoz2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def longest_word_length(words_raw):\n",
    "    if len(words_raw) ==0:\n",
    "        return 0\n",
    "    return max(len(word) for word in words_raw) \n",
    "\n",
    "#################################################################################################################################\n",
    "#               shortest word length in raw word list (Sahingoz2019)\n",
    "#################################################################################################################################\n",
    "\n",
    "def shortest_word_length(words_raw):\n",
    "    if len(words_raw) ==0:\n",
    "        return 0\n",
    "    return min(len(word) for word in words_raw) \n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               prefix suffix\n",
    "#################################################################################################################################\n",
    "\n",
    "def prefix_suffix(url):\n",
    "    if re.findall(r\"https?://[^\\-]+-[^\\-]+/\", url):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "#################################################################################################################################\n",
    "#               count subdomain\n",
    "#################################################################################################################################\n",
    "\n",
    "def count_subdomain(url):\n",
    "    if len(re.findall(\"\\.\", url)) == 1:\n",
    "        return 1\n",
    "    elif len(re.findall(\"\\.\", url)) == 2:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Suspecious TLD\n",
    "#################################################################################################################################\n",
    "\n",
    "suspecious_tlds = ['fit','tk', 'gp', 'ga', 'work', 'ml', 'date', 'wang', 'men', 'icu', 'online', 'click', # Spamhaus\n",
    "        'country', 'stream', 'download', 'xin', 'racing', 'jetzt',\n",
    "        'ren', 'mom', 'party', 'review', 'trade', 'accountants', \n",
    "        'science', 'work', 'ninja', 'xyz', 'faith', 'zip', 'cricket', 'win',\n",
    "        'accountant', 'realtor', 'top', 'christmas', 'gdn', # Shady Top-Level Domains\n",
    "        'link', # Blue Coat Systems\n",
    "        'asia', 'club', 'la', 'ae', 'exposed', 'pe', 'go.id', 'rs', 'k12.pa.us', 'or.kr',\n",
    "        'ce.ke', 'audio', 'gob.pe', 'gov.az', 'website', 'bj', 'mx', 'media', 'sa.gov.au' # statistics\n",
    "        ]\n",
    "\n",
    "\n",
    "def suspecious_tld(tld):\n",
    "   if tld in suspecious_tlds:\n",
    "       return 1\n",
    "   return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab data about url from sites\n",
    "# copied from https://data.mendeley.com/datasets/c2gw7fy2j4/3/files/562f107e-e96e-47f9-8635-a326b1d5fae4\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import whois\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Domain registration age \n",
    "#################################################################################################################################\n",
    "\n",
    "def domain_registration_length(domain):\n",
    "    try:\n",
    "        res = whois.whois(domain)\n",
    "        expiration_date = res.expiration_date\n",
    "        today = time.strftime('%Y-%m-%d')\n",
    "        today = datetime.strptime(today, '%Y-%m-%d')\n",
    "        # Some domains do not have expiration dates. The application should not raise an error if this is the case.\n",
    "        if expiration_date:\n",
    "            if type(expiration_date) == list:\n",
    "                expiration_date = min(expiration_date)\n",
    "            return abs((expiration_date - today).days)\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "def domain_registration_length1(domain):\n",
    "    v1 = -1\n",
    "    v2 = -1\n",
    "    try:\n",
    "        host = whois.whois(domain)\n",
    "        hostname = host.domain_name\n",
    "        expiration_date = host.expiration_date\n",
    "        today = time.strftime('%Y-%m-%d')\n",
    "        today = datetime.strptime(today, '%Y-%m-%d')\n",
    "        if type(hostname) == list:\n",
    "            for host in hostname:\n",
    "                if re.search(host.lower(), domain):\n",
    "                    v1 = 0\n",
    "            v1= 1\n",
    "        else:\n",
    "            if re.search(hostname.lower(), domain):\n",
    "                v1 = 0\n",
    "            else:\n",
    "                v1= 1  \n",
    "        if expiration_date:\n",
    "            if type(expiration_date) == list:\n",
    "                expiration_date = min(expiration_date)\n",
    "            return abs((expiration_date - today).days)\n",
    "        else:\n",
    "            v2= 0\n",
    "    except:\n",
    "        v1 = 1\n",
    "        v2 = -1\n",
    "        return v1, v2\n",
    "    return v1, v2\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Domain recognized by WHOIS\n",
    "#################################################################################################################################\n",
    "\n",
    " \n",
    "def whois_registered_domain(domain):\n",
    "    try:\n",
    "        hostname = whois.whois(domain).domain_name\n",
    "        if type(hostname) == list:\n",
    "            for host in hostname:\n",
    "                if re.search(host.lower(), domain):\n",
    "                    return 0\n",
    "            return 1\n",
    "        else:\n",
    "            if re.search(hostname.lower(), domain):\n",
    "                return 0\n",
    "            else:\n",
    "                return 1     \n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Unable to get web traffic (Page Rank)\n",
    "#################################################################################################################################\n",
    "import urllib\n",
    "\n",
    "def web_traffic(short_url):\n",
    "        try:\n",
    "            rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + short_url).read(), \"xml\").find(\"REACH\")['RANK']\n",
    "        except:\n",
    "            return 0\n",
    "        return int(rank)\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Domain age of a url\n",
    "#################################################################################################################################\n",
    "\n",
    "import json\n",
    "\n",
    "def domain_age(domain):\n",
    "\n",
    "    url = domain.split(\"//\")[-1].split(\"/\")[0].split('?')[0]\n",
    "    show = \"https://input.payapi.io/v1/api/fraud/domain/age/\" + url\n",
    "    r = requests.get(show)\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        data = r.text\n",
    "        jsonToPython = json.loads(data)\n",
    "        result = jsonToPython['result']\n",
    "        if result == None:\n",
    "            return -2\n",
    "        else:\n",
    "            return result\n",
    "    else:       \n",
    "        return -1\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Global rank\n",
    "#################################################################################################################################\n",
    "\n",
    "def global_rank(domain):\n",
    "    rank_checker_response = requests.post(\"https://www.checkpagerank.net/index.php\", {\n",
    "        \"name\": domain\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        return int(re.findall(r\"Global Rank: ([0-9]+)\", rank_checker_response.text)[0])\n",
    "    except:\n",
    "        return -1\n",
    "\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Google index\n",
    "#################################################################################################################################\n",
    "\n",
    "\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "def google_index(url):\n",
    "    #time.sleep(.6)\n",
    "    user_agent =  'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36'\n",
    "    headers = {'User-Agent' : user_agent}\n",
    "    query = {'q': 'site:' + url}\n",
    "    google = \"https://www.google.com/search?\" + urlencode(query)\n",
    "    data = requests.get(google, headers=headers)\n",
    "    data.encoding = 'ISO-8859-1'\n",
    "    soup = BeautifulSoup(str(data.content), \"html.parser\")\n",
    "    try:\n",
    "        if 'Our systems have detected unusual traffic from your computer network.' in str(soup):\n",
    "            return -1\n",
    "        check = soup.find(id=\"rso\").find(\"div\").find(\"div\").find(\"a\")\n",
    "        #print(check)\n",
    "        if check and check['href']:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    except AttributeError:\n",
    "        return 1\n",
    "\n",
    "#print(google_index('http://www.google.com'))\n",
    "#################################################################################################################################\n",
    "#               DNSRecord  expiration length\n",
    "#################################################################################################################################\n",
    "\n",
    "import dns.resolver\n",
    "\n",
    "def dns_record(domain):\n",
    "    try:\n",
    "        nameservers = dns.resolver.query(domain,'NS')\n",
    "        if len(nameservers)>0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "#################################################################################################################################\n",
    "#               Page Rank from OPR\n",
    "#################################################################################################################################\n",
    "\n",
    "\n",
    "def page_rank(key, domain):\n",
    "    url = 'https://openpagerank.com/api/v1.0/getPageRank?domains%5B0%5D=' + domain\n",
    "    try:\n",
    "        request = requests.get(url, headers={'API-OPR':key})\n",
    "        result = request.json()\n",
    "        result = result['response'][0]['page_rank_integer']\n",
    "        if result:\n",
    "            return result\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Email Text', 'Email Type']\n",
      "['1', 'the other side of * galicismos * * galicismo * is a spanish term which names the improper introduction of french words which are spanish sounding and thus very deceptive to the ear . * galicismo * is often considered to be a * barbarismo * . what would be the term which designates the opposite phenomenon , that is unlawful words of spanish origin which may have crept into french ? can someone provide examples ? thank you joseph m kozono < kozonoj @ gunet . georgetown . edu >', 'Safe Email']\n"
     ]
    }
   ],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "def read_csv_into_objects(file_path):\n",
    "    rows = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        header = next(csv_reader)  # Skip header\n",
    "        print(header)\n",
    "        for row in csv_reader:\n",
    "            rows.append(row)\n",
    "    return header, rows\n",
    "\n",
    "email_file = \"data/Phishing_Email.csv\"\n",
    "_, emails = read_csv_into_objects(email_file)\n",
    "print(emails[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qty_dot_url', 'qty_hyphen_url', 'qty_underline_url', 'qty_slash_url', 'qty_questionmark_url', 'qty_equal_url', 'qty_at_url', 'qty_and_url', 'qty_exclamation_url', 'qty_space_url', 'qty_tilde_url', 'qty_comma_url', 'qty_plus_url', 'qty_asterisk_url', 'qty_hashtag_url', 'qty_dollar_url', 'qty_percent_url', 'qty_tld_url', 'length_url', 'qty_dot_domain', 'qty_hyphen_domain', 'qty_underline_domain', 'qty_slash_domain', 'qty_questionmark_domain', 'qty_equal_domain', 'qty_at_domain', 'qty_and_domain', 'qty_exclamation_domain', 'qty_space_domain', 'qty_tilde_domain', 'qty_comma_domain', 'qty_plus_domain', 'qty_asterisk_domain', 'qty_hashtag_domain', 'qty_dollar_domain', 'qty_percent_domain', 'qty_vowels_domain', 'domain_length', 'domain_in_ip', 'server_client_domain', 'qty_dot_directory', 'qty_hyphen_directory', 'qty_underline_directory', 'qty_slash_directory', 'qty_questionmark_directory', 'qty_equal_directory', 'qty_at_directory', 'qty_and_directory', 'qty_exclamation_directory', 'qty_space_directory', 'qty_tilde_directory', 'qty_comma_directory', 'qty_plus_directory', 'qty_asterisk_directory', 'qty_hashtag_directory', 'qty_dollar_directory', 'qty_percent_directory', 'directory_length', 'qty_dot_file', 'qty_hyphen_file', 'qty_underline_file', 'qty_slash_file', 'qty_questionmark_file', 'qty_equal_file', 'qty_at_file', 'qty_and_file', 'qty_exclamation_file', 'qty_space_file', 'qty_tilde_file', 'qty_comma_file', 'qty_plus_file', 'qty_asterisk_file', 'qty_hashtag_file', 'qty_dollar_file', 'qty_percent_file', 'file_length', 'qty_dot_params', 'qty_hyphen_params', 'qty_underline_params', 'qty_slash_params', 'qty_questionmark_params', 'qty_equal_params', 'qty_at_params', 'qty_and_params', 'qty_exclamation_params', 'qty_space_params', 'qty_tilde_params', 'qty_comma_params', 'qty_plus_params', 'qty_asterisk_params', 'qty_hashtag_params', 'qty_dollar_params', 'qty_percent_params', 'params_length', 'tld_present_params', 'qty_params', 'email_in_url', 'time_response', 'domain_spf', 'asn_ip', 'time_domain_activation', 'time_domain_expiration', 'qty_ip_resolved', 'qty_nameservers', 'qty_mx_servers', 'ttl_hostname', 'tls_ssl_certificate', 'qty_redirects', 'url_google_index', 'domain_google_index', 'url_shortened', 'phishing']\n",
      "(88647, 112)\n"
     ]
    }
   ],
   "source": [
    "site_file = \"Phishing-Dataset/dataset_full.csv\"\n",
    "headers, ps = read_csv_into_objects(site_file)\n",
    "\n",
    "def load_csv_to_numpy(filename):\n",
    "    data = np.genfromtxt(filename, delimiter=',', skip_header=1)  # Skip header\n",
    "    return data\n",
    "\n",
    "csv_data = load_csv_to_numpy(site_file)\n",
    "print(csv_data.shape)\n",
    "print(csv_data.shape)\n",
    "file_path = 'website_data.npy'\n",
    "np.save(file_path, csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 88647)\n",
      "(19, 88647)\n",
      "<class 'numpy.ndarray'>\n",
      "(21, 88647)\n",
      "21\n",
      "['qty_dot_url', 'qty_hyphen_url', 'qty_underline_url', 'qty_slash_url', 'qty_questionmark_url', 'qty_equal_url', 'qty_at_url', 'qty_and_url', 'qty_exclamation_url', 'qty_space_url', 'qty_tilde_url', 'qty_comma_url', 'qty_plus_url', 'qty_asterisk_url', 'qty_hashtag_url', 'qty_dollar_url', 'qty_percent_url', 'qty_tld_url', 'length_url', 'email_in_url', 'phishing']\n"
     ]
    }
   ],
   "source": [
    "trim_data = csv_data.transpose()\n",
    "print(trim_data.shape)\n",
    "a = np.delete(trim_data, np.s_[19:112:1], 0)\n",
    "trim_headers = np.delete(headers, np.s_[19:112:1]).tolist()\n",
    "\n",
    "\n",
    "print(a.shape)\n",
    "print(type(a))\n",
    "a=np.vstack([a,trim_data[96]])\n",
    "a=np.vstack([a,trim_data[111]])\n",
    "trim_headers.append(headers[96])\n",
    "trim_headers.append(headers[111])\n",
    "print(a.shape)\n",
    "print(len(trim_headers))\n",
    "print(trim_headers)\n",
    "\n",
    "#np.save(trimmed_file_path, a.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.  0.  2.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      " 81.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "trimmed_data = np.load(file_path)\n",
    "print(trimmed_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88647, 112)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88647,)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
