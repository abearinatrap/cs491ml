{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import tldextract\n",
    "from urllib.parse import urlparse\n",
    "from src.urlfunctions import *\n",
    "\n",
    "trimmed_file_path = 'trimmed_data.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol: https\n",
      "Domain: test.co.uk\n",
      "Directory: \n",
      "File: \n",
      "Parameters: ?help=1\n"
     ]
    }
   ],
   "source": [
    "url_regex = \"^(https?|ftp):\\/\\/([^\\/]+)\\/(([^\\/?]+\\/)*)?([^\\/?]+\\.\\w+)?(\\?([^=]+=[^&]+)(&([^=]+=[^&]+))*)?$\"\n",
    "url = \"https://test.co.uk/?help=1\"\n",
    "match = re.match(url_regex, url)\n",
    "\n",
    "def extract_urls_from_email(email_content):\n",
    "    # Regex to match URLs\n",
    "    url_pattern = r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\"\n",
    "\n",
    "    # Find all URLs in the email content\n",
    "    urls = re.findall(url_pattern, email_content)\n",
    "    return urls\n",
    "\n",
    "def getNumSuspiciousKeywords(email_content):\n",
    "    # need to somehow account for bypass word filter by using different letter\n",
    "    text_lower = email_content.lower()\n",
    "    keywords = [\"urgent update\", \"pay now\"]\n",
    "    keyword_count = 0\n",
    "    \n",
    "    # Iterate through the keywords and count occurrences in the text\n",
    "    for keyword in keywords:\n",
    "        # Check if the keyword (case-insensitive) is present in the text\n",
    "        if keyword.lower() in text_lower:\n",
    "            keyword_count += 1\n",
    "    \n",
    "    return keyword_count\n",
    "\n",
    "def getNumShortedUrls(email_content):\n",
    "    short_domains = ['goo.gl', 'jmp.by']\n",
    "    pattern = r'https?://(?:{})/\\S+'.format('|'.join(re.escape(domain) for domain in short_domains))\n",
    "    urls = re.findall(pattern, email_content)\n",
    "    \n",
    "    # Count the number of URLs found\n",
    "    return len(urls)\n",
    "\n",
    "def getNumIpAddresses(email_content):\n",
    "    ipv4_regex = \"\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b\"\n",
    "    ipv6_regex = \"(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))\"\n",
    "    \n",
    "    ipv4_addresses = re.findall(ipv4_regex, email_content)\n",
    "    ipv6_addresses = re.findall(ipv6_regex, email_content)\n",
    "    \n",
    "    return len(ipv4_addresses) + len(ipv6_addresses)\n",
    "\n",
    "if match:\n",
    "    protocol = match.group(1)\n",
    "    domain = match.group(2)\n",
    "    directory = match.group(3) if match.group(3) else \"\"  # Handle optional directory\n",
    "    file = match.group(4) if match.group(4) else \"\"\n",
    "    parameters = match.group(6) if match.group(6) else \"\"  # Handle optional parameters\n",
    "\n",
    "    print(\"Protocol:\", protocol)\n",
    "    print(\"Domain:\", domain)\n",
    "    print(\"Directory:\", directory)\n",
    "    print(\"File:\", file)\n",
    "    print(\"Parameters:\", parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['url', 'length_url', 'length_hostname', 'ip', 'nb_dots', 'nb_hyphens', 'nb_at', 'nb_qm', 'nb_and', 'nb_or', 'nb_eq', 'nb_underscore', 'nb_tilde', 'nb_percent', 'nb_slash', 'nb_star', 'nb_colon', 'nb_comma', 'nb_semicolumn', 'nb_dollar', 'nb_space', 'nb_www', 'nb_com', 'nb_dslash', 'http_in_path', 'https_token', 'ratio_digits_url', 'ratio_digits_host', 'punycode', 'port', 'tld_in_path', 'tld_in_subdomain', 'abnormal_subdomain', 'nb_subdomains', 'prefix_suffix', 'random_domain', 'shortening_service', 'path_extension', 'nb_redirection', 'nb_external_redirection', 'length_words_raw', 'char_repeat', 'shortest_words_raw', 'shortest_word_host', 'shortest_word_path', 'longest_words_raw', 'longest_word_host', 'longest_word_path', 'avg_words_raw', 'avg_word_host', 'avg_word_path', 'phish_hints', 'domain_in_brand', 'brand_in_subdomain', 'brand_in_path', 'suspecious_tld', 'statistical_report', 'nb_hyperlinks', 'ratio_intHyperlinks', 'ratio_extHyperlinks', 'ratio_nullHyperlinks', 'nb_extCSS', 'ratio_intRedirection', 'ratio_extRedirection', 'ratio_intErrors', 'ratio_extErrors', 'login_form', 'external_favicon', 'links_in_tags', 'submit_email', 'ratio_intMedia', 'ratio_extMedia', 'sfh', 'iframe', 'popup_window', 'safe_anchor', 'onmouseover', 'right_clic', 'empty_title', 'domain_in_title', 'domain_with_copyright', 'whois_registered_domain', 'domain_registration_length', 'domain_age', 'web_traffic', 'dns_record', 'google_index', 'page_rank', 'status']\n",
      "['http://www.crestonwood.com/router.php', '37', '19', '0', '3', '0', '0', '0', '0', '0', '0', '0', '0', '0', '3', '0', '1', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0.0', '0.0', '0', '0', '0', '0', '0', '3', '0', '0', '0', '0', '0', '0', '4', '4', '3', '3', '3', '11', '11', '6', '5.75', '7.0', '4.5', '0', '0', '0', '0', '0', '0', '17', '0.529411765', '0.470588235', '0', '0', '0', '0.875', '0', '0.5', '0', '0', '80.0', '0', '100.0', '0.0', '0', '0', '0', '0.0', '0', '0', '0', '0', '1', '0', '45', '-1', '0', '1', '1', '4', 'legitimate']\n",
      "['', 'Email Text', 'Email Type']\n",
      "['1', 'the other side of * galicismos * * galicismo * is a spanish term which names the improper introduction of french words which are spanish sounding and thus very deceptive to the ear . * galicismo * is often considered to be a * barbarismo * . what would be the term which designates the opposite phenomenon , that is unlawful words of spanish origin which may have crept into french ? can someone provide examples ? thank you joseph m kozono < kozonoj @ gunet . georgetown . edu >', 'Safe Email']\n"
     ]
    }
   ],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "def read_csv_into_objects(file_path):\n",
    "    rows = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile)\n",
    "        header = next(csv_reader)  # Skip header\n",
    "        print(header)\n",
    "        for row in csv_reader:\n",
    "            rows.append(row)\n",
    "    return header, rows\n",
    "\n",
    "email_file = \"data/dataset_phishing.csv\"\n",
    "_, emails = read_csv_into_objects(email_file)\n",
    "print(emails[0])\n",
    "email_file = \"data/Phishing_Email.csv\"\n",
    "_, emails = read_csv_into_objects(email_file)\n",
    "print(emails[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getNumIpAddresses(\"http://shadetreetechnology.com/V4/validation/a111aedc8ae390eabcfa130e041a10a4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qty_dot_url', 'qty_hyphen_url', 'qty_underline_url', 'qty_slash_url', 'qty_questionmark_url', 'qty_equal_url', 'qty_at_url', 'qty_and_url', 'qty_exclamation_url', 'qty_space_url', 'qty_tilde_url', 'qty_comma_url', 'qty_plus_url', 'qty_asterisk_url', 'qty_hashtag_url', 'qty_dollar_url', 'qty_percent_url', 'qty_tld_url', 'length_url', 'qty_dot_domain', 'qty_hyphen_domain', 'qty_underline_domain', 'qty_slash_domain', 'qty_questionmark_domain', 'qty_equal_domain', 'qty_at_domain', 'qty_and_domain', 'qty_exclamation_domain', 'qty_space_domain', 'qty_tilde_domain', 'qty_comma_domain', 'qty_plus_domain', 'qty_asterisk_domain', 'qty_hashtag_domain', 'qty_dollar_domain', 'qty_percent_domain', 'qty_vowels_domain', 'domain_length', 'domain_in_ip', 'server_client_domain', 'qty_dot_directory', 'qty_hyphen_directory', 'qty_underline_directory', 'qty_slash_directory', 'qty_questionmark_directory', 'qty_equal_directory', 'qty_at_directory', 'qty_and_directory', 'qty_exclamation_directory', 'qty_space_directory', 'qty_tilde_directory', 'qty_comma_directory', 'qty_plus_directory', 'qty_asterisk_directory', 'qty_hashtag_directory', 'qty_dollar_directory', 'qty_percent_directory', 'directory_length', 'qty_dot_file', 'qty_hyphen_file', 'qty_underline_file', 'qty_slash_file', 'qty_questionmark_file', 'qty_equal_file', 'qty_at_file', 'qty_and_file', 'qty_exclamation_file', 'qty_space_file', 'qty_tilde_file', 'qty_comma_file', 'qty_plus_file', 'qty_asterisk_file', 'qty_hashtag_file', 'qty_dollar_file', 'qty_percent_file', 'file_length', 'qty_dot_params', 'qty_hyphen_params', 'qty_underline_params', 'qty_slash_params', 'qty_questionmark_params', 'qty_equal_params', 'qty_at_params', 'qty_and_params', 'qty_exclamation_params', 'qty_space_params', 'qty_tilde_params', 'qty_comma_params', 'qty_plus_params', 'qty_asterisk_params', 'qty_hashtag_params', 'qty_dollar_params', 'qty_percent_params', 'params_length', 'tld_present_params', 'qty_params', 'email_in_url', 'time_response', 'domain_spf', 'asn_ip', 'time_domain_activation', 'time_domain_expiration', 'qty_ip_resolved', 'qty_nameservers', 'qty_mx_servers', 'ttl_hostname', 'tls_ssl_certificate', 'qty_redirects', 'url_google_index', 'domain_google_index', 'url_shortened', 'phishing']\n",
      "(88647, 112)\n"
     ]
    }
   ],
   "source": [
    "site_file = \"Phishing-Dataset/dataset_full.csv\"\n",
    "headers, ps = read_csv_into_objects(site_file)\n",
    "\n",
    "def load_csv_to_numpy(filename):\n",
    "    data = np.genfromtxt(filename, delimiter=',', skip_header=1)  # Skip header\n",
    "    return data\n",
    "\n",
    "csv_data = load_csv_to_numpy(site_file)\n",
    "print(csv_data.shape)\n",
    "print(csv_data.shape)\n",
    "file_path = 'website_data.npy'\n",
    "np.save(file_path, csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 88647)\n",
      "(19, 88647)\n",
      "<class 'numpy.ndarray'>\n",
      "(21, 88647)\n",
      "21\n",
      "['qty_dot_url', 'qty_hyphen_url', 'qty_underline_url', 'qty_slash_url', 'qty_questionmark_url', 'qty_equal_url', 'qty_at_url', 'qty_and_url', 'qty_exclamation_url', 'qty_space_url', 'qty_tilde_url', 'qty_comma_url', 'qty_plus_url', 'qty_asterisk_url', 'qty_hashtag_url', 'qty_dollar_url', 'qty_percent_url', 'qty_tld_url', 'length_url', 'email_in_url', 'phishing']\n"
     ]
    }
   ],
   "source": [
    "trim_data = csv_data.transpose()\n",
    "print(trim_data.shape)\n",
    "a = np.delete(trim_data, np.s_[19:112:1], 0)\n",
    "trim_headers = np.delete(headers, np.s_[19:112:1]).tolist()\n",
    "\n",
    "\n",
    "print(a.shape)\n",
    "print(type(a))\n",
    "a=np.vstack([a,trim_data[96]])\n",
    "a=np.vstack([a,trim_data[111]])\n",
    "trim_headers.append(headers[96])\n",
    "trim_headers.append(headers[111])\n",
    "print(a.shape)\n",
    "print(len(trim_headers))\n",
    "print(trim_headers)\n",
    "\n",
    "#np.save(trimmed_file_path, a.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.  0.  2.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      " 81.  0.  1.]\n",
      "column 0: float64\n",
      "column 1: float64\n",
      "column 2: float64\n",
      "column 3: float64\n",
      "column 4: float64\n",
      "column 5: float64\n",
      "column 6: float64\n",
      "column 7: float64\n",
      "column 8: float64\n",
      "column 9: float64\n",
      "column 10: float64\n",
      "column 11: float64\n",
      "column 12: float64\n",
      "column 13: float64\n",
      "column 14: float64\n",
      "column 15: float64\n",
      "column 16: float64\n",
      "column 17: float64\n",
      "column 18: float64\n",
      "column 19: float64\n",
      "column 20: float64\n"
     ]
    }
   ],
   "source": [
    "trimmed_data = np.load(trimmed_file_path)\n",
    "print(trimmed_data[3])\n",
    "for cidx in range(trimmed_data.shape[1]):\n",
    "    cdt = trimmed_data[:,cidx].dtype\n",
    "    print(f\"column {cidx}: {cdt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://www.google.com\"\n",
    "hostname, domain, path = get_domain(url)\n",
    "extracted_domain = tldextract.extract(url)\n",
    "domain = extracted_domain.domain+'.'+extracted_domain.suffix\n",
    "subdomain = extracted_domain.subdomain\n",
    "tmp = url[url.find(extracted_domain.suffix):len(url)]\n",
    "pth = tmp.partition(\"/\")\n",
    "path = pth[1] + pth[2]\n",
    "parsed = urlparse(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.google.com google.com \n"
     ]
    }
   ],
   "source": [
    "print(hostname, domain, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11184, 46)\n",
      "(11161, 46)\n",
      "(11161, 46)\n",
      "(11161, 46)\n",
      "[37 19  3  0  0  0  0  0  0  0  0  0  3  0  1  0  0  0  0  1  0  0  0  1\n",
      "  0  0  0  0  0  3  0  0  4  0  0  0  0  0  0 45 -1  0  1  1  4  0]\n",
      "(46,)\n"
     ]
    }
   ],
   "source": [
    "# transform csv into ML learnable data\n",
    "df = pd.read_csv(\"data/selected_columns_1.csv\")\n",
    "#df = pd.read_csv(\"data/selected_columns_1.csv\", sep=\",\", skipinitialspace=True)\n",
    "# remove url\n",
    "df = df.iloc[:, 1:]\n",
    "\n",
    "\n",
    "# turn label into number\n",
    "df['status'] = df['status'].map({'legitimate': 0, 'phishing': 1})\n",
    "print(df.shape)\n",
    "\n",
    "for column in df.columns:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "df=df.dropna()\n",
    "\n",
    "#df['status'] = df['status'].astype(int)\n",
    "\n",
    "float_col = df.select_dtypes(include=['float64'])\n",
    "for col in float_col.columns.values:\n",
    "    df[col] = df[col].astype('int64')\n",
    "\n",
    "print(df.shape)\n",
    "csv = df.to_csv(\"data/test.csv\")\n",
    "\n",
    "\n",
    "#df['status'] = df['status'].astype(int)\n",
    "\n",
    "# URL WITH COMMA is causing trouble because pandas isn't respecting the double quote...... delete for now\n",
    "#print(df.isna())\n",
    "\n",
    "# convert to numpy\n",
    "#scn = df.to_numpy()\n",
    "scn = df.to_numpy(na_value=0)\n",
    "\n",
    "scn[0] = scn[0].astype(int)\n",
    "print(scn.shape)\n",
    "#print(scn)\n",
    "\n",
    "# convert to numpy\n",
    "scn = df.to_numpy()\n",
    "#for cidx in range(scn.shape[1]):\n",
    "#    cdt = scn[:,cidx].dtype\n",
    "#    print(f\"column {cidx}: {cdt}\")\n",
    "\n",
    "print(scn.shape)\n",
    "print(scn[0])\n",
    "print(scn[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8928, 46)\n",
      "(2233, 46)\n"
     ]
    }
   ],
   "source": [
    "scn_filename = 'website_data_more.npy'\n",
    "np.save(scn_filename, scn)\n",
    "\n",
    "np.random.shuffle(scn)\n",
    "split_ratio = 0.8\n",
    "si = int(split_ratio * len(scn))\n",
    "train_data = scn[:si]\n",
    "test_data = scn[si:]\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "np.save(\"2train.npy\", train_data)\n",
    "np.save(\"2test.npy\", test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
