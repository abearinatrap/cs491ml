{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import tldextract\n",
    "import torch\n",
    "from src.NeuralNetwork import NeuralNetwork\n",
    "from src.urlfunctions import *\n",
    "import urllib\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "email_pattern = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_domain(url):\n",
    "    o = urllib.parse.urlsplit(url)\n",
    "    return o.hostname, tldextract.extract(url).domain, o.path\n",
    "\n",
    "def words_raw_extraction(domain, subdomain, path):\n",
    "    w_domain = re.split(\"\\-|\\.|\\/|\\?|\\=|\\@|\\&|\\%|\\:|\\_\", domain.lower())\n",
    "    w_subdomain = re.split(\"\\-|\\.|\\/|\\?|\\=|\\@|\\&|\\%|\\:|\\_\", subdomain.lower())   \n",
    "    w_path = re.split(\"\\-|\\.|\\/|\\?|\\=|\\@|\\&|\\%|\\:|\\_\", path.lower())\n",
    "    raw_words = w_domain + w_path + w_subdomain\n",
    "    w_host = w_domain + w_subdomain\n",
    "    raw_words = list(filter(None,raw_words))\n",
    "    return raw_words, list(filter(None,w_host)), list(filter(None,w_path))\n",
    "\n",
    "allbrand_txt = open(\"data/allbrands.txt\", \"r\")\n",
    "\n",
    "def __txt_to_list(txt_object):\n",
    "    list = []\n",
    "    for line in txt_object:\n",
    "        list.append(line.strip())\n",
    "    txt_object.close()\n",
    "    return list\n",
    "\n",
    "allbrand = __txt_to_list(allbrand_txt)\n",
    "\n",
    "def domain_in_brand(domain):   \n",
    "    if domain in allbrand:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def brand_in_path(domain,path):\n",
    "    for b in allbrand:\n",
    "        if '.'+b+'.' in path and b not in domain:\n",
    "           return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.crestonwood.com/router.php\"\n",
    "\n",
    "hostname, domain, path = get_domain(url)\n",
    "tldinfo = tldextract.extract(url)\n",
    "domain = tldinfo.domain+'.'+tldinfo.suffix\n",
    "subdomain = tldinfo.subdomain\n",
    "tld = tldinfo.suffix\n",
    "\n",
    "tmp = url[url.find(tldinfo.suffix):len(url)]\n",
    "pth = tmp.partition(\"/\")\n",
    "path = pth[1] + pth[2]\n",
    "\n",
    "words_raw, words_raw_host, words_raw_path= words_raw_extraction(tldinfo.domain, subdomain, pth[2])\n",
    "\n",
    "parsed = urlparse(url)\n",
    "scheme = parsed.scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"url.count('/')\n",
    "url.count('*')\n",
    "url.count(\":\")\n",
    "url.count(',')\n",
    "url.count(';')\n",
    "url.count('$')\n",
    "url.count(' ')\n",
    "url.count('www')\n",
    "url.count('com')\n",
    "count_double_slash(url)\n",
    "count_http_token(url)\n",
    "https_token(scheme)\n",
    "punycode(url)\n",
    "port(url)\n",
    "tld_in_path(tld,path)\n",
    "tld_in_subdomain(tld,subdomain)\n",
    "abnormal_subdomain(url)\n",
    "count_subdomain(url)\n",
    "prefix_suffix(url)\n",
    "shortening_service(url)\n",
    "char_repeat(words_raw)\n",
    "phish_hints(url)\n",
    "domain_in_brand(domain)\n",
    "brand_in_path(subdomain)\n",
    "brand_in_path(path)\n",
    "suspecious_tld(tld)\n",
    "whois_registered_domain(domain)\n",
    "domain_registration_length(domain)\n",
    "domain_age(domain)\n",
    "web_traffic(url)\n",
    "dns_record(domain)\n",
    "google_index(url)\n",
    "0\"\"\"\n",
    "\n",
    "l=s.split(\"\\n\")\n",
    "#print(l)\n",
    "for i in range(len(l)):\n",
    "    #print(f\"output[{12+i}] = {l[i]}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.ndarray(45, dtype=int)\n",
    "output[0] = len(url)\n",
    "output[1] = len(hostname)\n",
    "output[2] = url.count(\".\")\n",
    "output[3] = url.count(\"-\")\n",
    "output[4] = url.count(\"@\")\n",
    "output[5] = url.count(\"?\")\n",
    "output[6] = url.count(\"&\")\n",
    "output[7] = url.count('|')\n",
    "output[8] = url.count('=')\n",
    "output[9] = url.count(\"_\")\n",
    "output[10] = url.count(\"~\")\n",
    "output[11] = url.count(\"%\")\n",
    "output[12] = url.count('/')\n",
    "output[13] = url.count('*')\n",
    "output[14] = url.count(\":\")\n",
    "output[15] = url.count(',')\n",
    "output[16] = url.count(';')\n",
    "output[17] = url.count('$')\n",
    "output[18] = url.count(' ')\n",
    "output[19] = url.count('www')\n",
    "output[20] = url.count('com')\n",
    "output[21] = count_double_slash(url)\n",
    "output[22] = count_http_token(url)\n",
    "output[23] = https_token(scheme)\n",
    "output[24] = punycode(url)\n",
    "output[25] = port(url)\n",
    "output[26] = tld_in_path(tld,path)\n",
    "output[27] = tld_in_subdomain(tld,subdomain)\n",
    "output[28] = abnormal_subdomain(url)\n",
    "output[29] = count_subdomain(url)\n",
    "output[30] = prefix_suffix(url)\n",
    "output[31] = shortening_service(url)\n",
    "output[32] = char_repeat(words_raw)\n",
    "output[33] = phish_hints(url)\n",
    "output[34] = domain_in_brand(domain)\n",
    "output[35] = brand_in_path(tldinfo.domain, subdomain)\n",
    "output[36] = brand_in_path(tldinfo.domain, path)\n",
    "output[37] = suspecious_tld(tld)\n",
    "output[38] = whois_registered_domain(domain)\n",
    "output[39] = domain_registration_length(domain)\n",
    "output[40] = -2 #domain_age(domain)\n",
    "output[41] = web_traffic(url)\n",
    "output[42] = dns_record(domain)\n",
    "output[43] = google_index(url)\n",
    "output[44] = 4 # page_rank when we get openpagerank api key\n",
    "\n",
    "\n",
    "m_input = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4167], device='cuda:0')\n",
      "Model prediction for the input: False\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.tensor(m_input, dtype=torch.float32).to(device)\n",
    "#input_tensor = input_tensor.view(1, -1)\n",
    "\n",
    "input_size = 45\n",
    "output_size = 1\n",
    "\n",
    "hidden_size = 40\n",
    "num_hidden_layers = 10\n",
    "model_path = \"trained_weights/neural/scn_0.002_11_10_40.pth\"\n",
    "\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size, num_hidden_layers).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "print(torch.sigmoid(output))\n",
    "predicted_class = torch.sigmoid(output) >= 0.5\n",
    "\n",
    "print(\"Model prediction for the input:\", predicted_class.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11161, 46)\n",
      "(11161, 45)\n",
      "(45,)\n",
      "(45,)\n",
      "[37 19  3  0  0  0  0  0  0  0  0  0  3  0  1  0  0  0  0  1  1  0  1  1\n",
      "  0  0  0  0  0  3  0  0  4  0  0  0  0  0  1 -1 -2  0  0  1  0]\n",
      "[37 19  3  0  0  0  0  0  0  0  0  0  3  0  1  0  0  0  0  1  0  0  0  1\n",
      "  0  0  0  0  0  3  0  0  4  0  0  0  0  0  0 45 -1  0  1  1  4]\n",
      "37 : 37\n",
      "19 : 19\n",
      "3 : 3\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "3 : 3\n",
      "0 : 0\n",
      "1 : 1\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "1 : 1\n",
      "1 : 0\n",
      "0 : 0\n",
      "1 : 0\n",
      "1 : 1\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "3 : 3\n",
      "0 : 0\n",
      "0 : 0\n",
      "4 : 4\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "0 : 0\n",
      "1 : 0\n",
      "-1 : 45\n",
      "-2 : -1\n",
      "0 : 0\n",
      "0 : 1\n",
      "1 : 1\n",
      "0 : 4\n"
     ]
    }
   ],
   "source": [
    "data_array = np.load(\"website_data_more.npy\")\n",
    "print(data_array.shape)\n",
    "features = data_array[:,:-1]\n",
    "print(features.shape)\n",
    "print(m_input.shape)\n",
    "print(features[0].shape)\n",
    "print(m_input)\n",
    "print(features[0])\n",
    "\n",
    "num = 0\n",
    "\n",
    "for i in range(45):\n",
    "    print(f\"{m_input[i]} : {features[0][i]}\")\n",
    "    \n",
    "while True:\n",
    "    break\n",
    "    input_tensor = torch.tensor(features[num], dtype=torch.float32).to(device)\n",
    "    #input_tensor = input_tensor.view(1, -1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    print(torch.sigmoid(output))\n",
    "    predicted_class = torch.sigmoid(output) >= 0.5\n",
    "\n",
    "    print(\"Model prediction for the input:\", predicted_class.item())\n",
    "    num+=1\n",
    "    input()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
